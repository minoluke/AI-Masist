# MASist Configuration (AI-Scientist-v2 準拠)
# マルチエージェントシミュレーション用設定

# path to the task data directory
data_dir: "data"
preprocess_data: False

goal: null
eval: null

log_dir: logs
workspace_dir: workspaces

# whether to copy the data to the workspace directory (otherwise it will be symlinked)
# copying is recommended to prevent the agent from accidentally modifying the original data
copy_data: True

exp_name: run # a random experiment name will be generated if not provided

# settings for code execution
exec:
  timeout: 3600
  agent_file_name: runfile.py
  format_tb_ipython: False

generate_report: True

# Final plot aggregation settings
aggregate_plots: true
agg_plots_model: "deepseek-chat"
agg_plots_reflections: 5

# Paper writeup settings
perform_writeup: true
writeup_small_model: "deepseek-chat"       # 引用収集等の軽量タスク
writeup_big_model: "deepseek-reasoner"     # 論文本文生成（推論が必要）
writeup_reflections: 3
writeup_page_limit: 4

# Citation gathering settings
gather_citations: true
num_cite_rounds: 20

# Review settings
perform_review: true
review_model: "deepseek-chat"              # テキストレビュー
vlm_model: "gpt-4o-mini"                   # 画像レビュー（VLMはOpenAIのみ）

# LLM settings for final report from journal
report:
  model: deepseek-chat
  temp: 1.0
  thinking:
    type: disabled
    budget_tokens: null
  betas: ""
  max_tokens: null

experiment:
  num_syn_datasets: 1

debug:
  stage4: False

# agent hyperparams
agent:
  type: parallel
  num_workers: 4
  stages:
    stage1_max_iters: 20
    stage2_max_iters: 12
    stage3_max_iters: 12
    stage4_max_iters: 18
  # how many improvement iterations to run
  steps: 20 # if stage-specific max_iters are not provided, the agent will use this value for all stages
  # whether to instruct the agent to use CV (set to 1 to disable)
  k_fold_validation: 1
  multi_seed_eval:
    num_seeds: 3 # should be the same as num_workers if num_workers < 3. Otherwise, set it to be 3.
  # whether to provide the agent with a preview of the data
  data_preview: False

  # LLM settings for coding
  code:
    model: deepseek-chat
    temp: 1.0
    max_tokens: 12000
    thinking:
      type: disabled
      budget_tokens: null
    betas: ""

  # LLM settings for evaluating program output / tracebacks
  feedback:
    model: deepseek-chat
    temp: 0.5
    max_tokens: 8192
    thinking:
      type: disabled
      budget_tokens: null
    betas: ""

  vlm_feedback:
    model: gpt-4o-mini
    temp: 0.5
    max_tokens: null
    thinking:
      type: disabled
      budget_tokens: null
    betas: ""

  search:
    max_debug_depth: 3
    debug_prob: 0.5
    num_drafts: 4

  # MASist extension: settings for generated agent simulation code
  agent_simulation:
    model: deepseek-chat
    temp: 0.7
    api_key_env: DEEPSEEK_API_KEY
    base_url: https://api.deepseek.com
    timeout: 60

  # Options for summarizing findings and selecting the best node
  # If not specified, the default behavior will be used.

  # summary:
  #   model: gpt-4o
  #   temp: 0.3
  #   thinking:
  #     type: disabled
  #     budget_tokens: null
  #   betas: ""
  #   max_tokens: null

  # select_node:
  #   model: gpt-4o
  #   temp: 0.3
  #   thinking:
  #     type: disabled
  #     budget_tokens: null
  #   betas: ""
  #   max_tokens: null
